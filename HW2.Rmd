---
title: "hw2 Ds 303"
author: "Alexis Maldonado"
date: "9/7/2023"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

1.a
True values for 
beta 0 = 2
beta 1 = 3
beta 2 = 5

1.b
```{r}
X1 = seq(0,10,length.out =100)
X2 = runif(100)

beta0 = 2
beta1 = 3
beta2 = 5

error = rnorm(100,0,1)
y = beta0 + beta1*X1 + beta2*X2 + error

y
```

1.c
We can clearly see that there is a linear ralationship with X1 and Y.
However there is no real relationship on can assume from the plot of X2 and Y.
```{r}
plot(x = X1, y = y, xlab = "X1", ylab = "Y", main = "X1 vs Y")

plot(x = X2, y = y, xlab = "X2", ylab = "Y", main = "X2 vs Y")
```

1.d
```{r}
beta0 = 2
beta1 = 3
beta2 = 5 

firstco = 0
secondco = 0

genBeta1 <- c(rep(1, 100))


for(i in  1:100){
X1 = seq(0,10, length.out =100)

error = rnorm(100,0,1)
Y = beta0 + beta1*X1 + error 

model = lm(Y~X1)
  
firstco = firstco + model$coefficient[1]
secondco = secondco + model$coefficient[2]

genBeta1[i] = coefficients(model)[2]
}
firstco/100
secondco/100
```

1.e
```{r}
hist(genBeta1, xlab = "Beta_1",
     col = "Blue", border = "black")
abline(v = 3, col = "orange", lwd = 5)
```

1.f
```{r}
beta0 = 2
beta1 = 3
beta2 = 5 

firstco = 0
secondco = 0
thirdco = 0

genBeta2 <- c(rep(1, 100))


for(i in  1:100){
X1 = seq(0,10, length.out =100)
X2 = runif(100)

error = rnorm(100,0,1)
Y = beta0 + beta1*X1 + beta2*log(X2) + error 

model = lm(Y~X1 + log(X2))
model
firstco = firstco + model$coefficient[1]
secondco = secondco + model$coefficient[2]
thirdco = thirdco + model$coefficient[3]

genBeta2[i] = coefficients(model)[3]
}
firstco/100
secondco/100
thirdco/100
```

1.g
```{r}
hist(genBeta2, xlab = "Beta_1",
     col = "Blue", border = "black")
abline(v = 5, col = "orange", lwd = 5)
```

1.h 
WTS var(ei) =  1/n-1 sum( (ei - e)^2, i = 1, 100) = 0


1.i
0

-----------------------------------------------------------------------
2.a 
True because its expressed correctly


2.b
False because when training you would expect the mse to be lower however there is no way to always be sure it will be.

2.c
False because although the formula looks good the y0 are value we are trying to predict rather than values from the training set

2.d
True because like discussed in class if we have avery complex model, it might fit the training model very well but not the overall test model (overfit).

2.e
False, irreducible error is constant and small and is there to account for randomness because of the test mse can not be lower than it.

2.f
True unlike test the training mse can be lower than irreducible error because we can make the model fit the data better

2.g
This could be problematic because it wouldnt be linearly independet anymore. 

2.h
The RSS changes base on the predictor that is added to it.For example if a predictor has a significant relationship then it might decrease RSS creating a better model, if the new predictor doesnt help predict and doesnt not make it worse it will remain the same and if the predictor has no significance at all it can increase the RSS.

-----------------------------------------------------------------------
3.a
```{r}
beta0 = 1
beta1 = 1
beta2 = 1

X1 = seq(0,5,length.out =100)
error = rnorm(100,0,1)
Y = beta0 + beta1*X1 + beta2*X1^2 + error 
plot(x = X1, y = Y, xlab = "X2", ylab = "Y", main = "X1 vs Y")
```

3.b
```{r}
values = matrix(0, 1000, 5)

for (i in 1:1000) {
  error = rnorm(100,0,1)
  Y = beta0 + beta1*X1 + beta2*X1^2 + error 
  for (j in 1:5) {
    values[i, j] = predict(lm(Y ~ poly(X1, j)), newdata = data.frame(X1 = 1))
  }
}

head(values, 5)
```

3.c
```{r}
x0 = rep(1, 1000)

beta0 = 1
beta1 = 1
beta2 = 1


error = rnorm(1000,0,1)
y0 = beta0 + beta1*x0 + beta2*x0 + error

head(y0, 5)
```

3.dm4 has the smallest mse
```{r}
test_mse = numeric(1000)
for (j in 1:5) {
  for(i in 1:1000){
    mse = mean((y0 - values[i, j])^2)
    test_mse[j] = mse
  }
  print(mean(test_mse[j]))
}

```

3.e
```{r}
mse_values = c(test_mse[1],test_mse[2],test_mse[3],test_mse[4],test_mse[5])
plot(1:5, mse_values, type = "b", 
     xlab = "complexity", ylab = "Mse test",
     main = "mse test v Complexity")


```

3.f
When we increased the complexity we saw a shift in lowering the mse, this occured since there was more flexibilty it fited the model better